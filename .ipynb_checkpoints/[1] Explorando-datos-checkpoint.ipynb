{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freemium Estadística para Data Analysis\n",
    "---\n",
    "\n",
    "El hundimiento del Titanic es uno de los naufragios más infames de la historia.\n",
    "\n",
    "El 15 de abril de 1912, durante su viaje inaugural, el ampliamente considerado \"insumergible\" RMS Titanic se hundió después de chocar con un iceberg. Desafortunadamente, no había suficientes botes salvavidas para todos a bordo, lo que resultó en la muerte de 1502 de 2224 pasajeros y tripulantes.\n",
    "\n",
    "Si bien hubo algún elemento de suerte involucrado en la supervivencia, parece que algunos grupos de personas tenían más probabilidades de sobrevivir que otros.\n",
    "\n",
    "Durante este curso, utilizaremos datos reales del Titanic para **calcular probabilidades y expectativas condicionales, de los pasajeros.**\n",
    "\n",
    "Como comentamos en los videos, el primer paso de cualquier analista de datos es explorar, entender y limpiar los datos. **Todo analysis comienza con datos.**\n",
    "\n",
    "Para este análisis, no es necesario saber programar, ni usar python. Pero por simplicidad de visualización haremos este ejercicio usando Python 3.7 y la librería Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorar datos\n",
    "---\n",
    "Nuestro primer paso es entender qué tipos de datos y estructura estaremos trabajando, por lo tanto lo primero que haremos es leer el archivo csv. Puedes encontrar los datos, junto a una descripción en Kaggle, [data](https://www.kaggle.com/c/titanic/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'titanic.csv'\n",
    "df = pd.read_csv(csv_file, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que estamos lidiando con valores enteros, objetos y decimales. Divididos en 12 columnas y contamos con un *universo* de 891 entradas o pasajeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También queremos saber cuales son las propiedades de cada entrada, esto está representado en columnas. Ahora que entendemos que tipo de información estamos utilizando podemos comenzar a crear hipótesis y a obtener información *simple* que nos permite crear bloques de datos para su análisis.\n",
    "\n",
    "Algo importante que recalcar es que todas las bases tienen datos *codificados*, esto quiere decir que un dato en una columna específica tiene un significado, por ejemplo en el caso de nuestros datos la columna *SibSP* puede tener dos tipos de llaves 0 y 1, donde 0 = falso y 1 = verdadero.\n",
    "\n",
    "Es importante entender esta información antes de comenzar el análisis. En nuestro caso está  codificada de la siguiente forma\n",
    "\n",
    "| Columna | Definicion | Llave \n",
    "| ----------- | ----------- | -----------\n",
    "| Survival | Sobrevivo? | 0=No, 1=Si\n",
    "| Pclass | Clase | \t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "| Sex | Sexo | female=Mujer, male=Hombre\n",
    "| Age | Años | \n",
    "| Sibsp | #de herman@s / cónyuges a bordo del Titanic\n",
    "| Parch | #de padres / Niñ@s a bordo del Titanic \n",
    "| Ticket | Numero de ticket |\n",
    "| Fare | Tarifa de pasajero |\n",
    "| Cbin | Cabina |\n",
    "| Embarked | Puerto de embarque | C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiando datos\n",
    "---\n",
    "Retomando lo comentado en los videos, el paso clave después del análisis previo es la limpieza de datos, dentro de nuestro dataset, no es necesarias las columnas de Nombre, Ticket ni Cabina, ya que esto no nos ayuda a predecir la supervivencia. Por lo tanto los eliminamos de nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Sex          891 non-null    object \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Fare         891 non-null    float64\n",
      " 8   Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "cols = ['Name', 'Ticket', 'Cabin']\n",
    "df = df.drop(cols, axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, si queremos, podemos eliminar todas las filas de los datos que tienen valores faltantes (NaN). Esto es importante para que no tengamos errores de cálculos futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Survived     712 non-null    int64  \n",
      " 2   Pclass       712 non-null    int64  \n",
      " 3   Sex          712 non-null    object \n",
      " 4   Age          712 non-null    float64\n",
      " 5   SibSp        712 non-null    int64  \n",
      " 6   Parch        712 non-null    int64  \n",
      " 7   Fare         712 non-null    float64\n",
      " 8   Embarked     712 non-null    object \n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 55.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dfna = df.dropna()\n",
    "dfna.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de eliminar las filas con valores NaN **el conjunto de datos se reduce a 712 filas de 891**, lo que significa que **estamos desperdiciando datos**. Por lo tanto, es necesario conservar datos, algo muy común en el análisis de datos es la creación de datos *dummy*, esto quiere decir que utilizamos datos promedio o que podemos encontrar dentro de nuestro mismo data set.\n",
    "Veamos cual de las columnas tiene mayor cantidad de datos vacíos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId: 0\n",
      "Survived: 0\n",
      "Pclass: 0\n",
      "Sex: 0\n",
      "Age: 177\n",
      "SibSp: 0\n",
      "Parch: 0\n",
      "Fare: 0\n",
      "Embarked: 2\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col + ': ' + str( df[col].isna().sum() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, estamos avanzando, la **edad cuenta con 177 campos vacíos** por lo tanto calcularemos la mediana o interpolar todas las edades y llenar esos valores de edad faltantes. Pandas tiene una función interpolar que reemplazará todos los NaN faltantes por valores interpolados.\n",
    "\n",
    "Puedes leer como mas acerca de esta función en la documentación de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId: 0\n",
      "Survived: 0\n",
      "Pclass: 0\n",
      "Sex: 0\n",
      "Age: 0\n",
      "SibSp: 0\n",
      "Parch: 0\n",
      "Fare: 0\n",
      "Embarked: 2\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col + ': ' + str( df[col].isna().sum() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de Embarked, podemos eliminar los valores vacíos ya que son pocos con respecto al universo que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  889 non-null    int64  \n",
      " 1   Survived     889 non-null    int64  \n",
      " 2   Pclass       889 non-null    int64  \n",
      " 3   Sex          889 non-null    object \n",
      " 4   Age          889 non-null    float64\n",
      " 5   SibSp        889 non-null    int64  \n",
      " 6   Parch        889 non-null    int64  \n",
      " 7   Fare         889 non-null    float64\n",
      " 8   Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 69.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma nos quedamos con un universo final de 889 pasajeros. En los siguientes videos comenzaremos a realizar un análisis de datos más profundo pero podemos comenzar a hacer un análisis somero de la información que tenemos por ejemplo podemos obtener el monto total que pagaron los pasajeros del Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 28 533.95\n"
     ]
    }
   ],
   "source": [
    "total = df['Fare'].sum()\n",
    "locale.setlocale( locale.LC_ALL, '' )\n",
    "print(locale.currency(total, grouping=True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podriamos saber cual es la media de edad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.68044994375703\n"
     ]
    }
   ],
   "source": [
    "mean = df['Age'].mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta sección cubre los conceptos más básicos, en las siguientes secciones explicaremos metodos y crearemos nuestro primer algoritmo para calcular la probabilidad de nuestro data set. Continua con nosotros\n",
    "\n",
    "©BEDU 2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedu-hs",
   "language": "python",
   "name": "bedu-hs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
